% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SOptim_FitnessFunctions.R
\name{fitFuncGeneric}
\alias{fitFuncGeneric}
\title{Fitness function used in genetic, random and grid search optimization algorithms}
\usage{
fitFuncGeneric(
  x,
  rstFeatures,
  trainData,
  segmentMethod,
  ...,
  trainThresh = 0.5,
  segmStatsFuns = c("mean", "sd"),
  bylayer = FALSE,
  tiles = NULL,
  classificationMethod = "RF",
  classificationMethodParams = NULL,
  balanceTrainData = FALSE,
  balanceMethod = "ubUnder",
  evalMethod = "5FCV",
  trainPerc = 0.8,
  nRounds = 20,
  evalMetric = "Kappa",
  minTrainCases = 30,
  minCasesByClassTrain = 10,
  minCasesByClassTest = 10,
  minImgSegm = 30,
  ndigits = 2,
  verbose = TRUE
)
}
\arguments{
\item{x}{Vector with segmentation parameters that will be optimized by the genetic algorithms from GA package.}

\item{rstFeatures}{Features used for supervised classification (typically a multi-layer raster with one feature 
per band). May be defined as a string with the path to a raster dataset or a \code{RasterStack} object.}

\item{trainData}{Input train data used for supervised classification. It can be a \code{RasterLayer} containing 
train areas (in raster format) or a \code{SpatialPointsDataFrame} object containing train points (in this case, 
the data must contain a column named "train" holding the train classes). For points you can use \link[rgdal]{readOGR} 
function to read input files (e.g., ESRI Shapefile) or use \link[sp]{SpatialPointsDataFrame} to create a valid 
data object within \code{R}.}

\item{segmentMethod}{Character string used to define the segmentation method. 
Available options are:     
\itemize{
  \item \code{"SAGA_SRG"} - SAGA Simple Region Growing;
  \item \code{"GRASS_RG"} - GRASS Region Growing;
  \item \code{"ArcGIS_MShift"} - ArcGIS Mean Shift algorithm;
  \item \code{"Terralib_Baatz"} - TerraLib Baatz algorithm;
  \item \code{"Terralib_MRGrow"} - TerraLib Mean Region Growing;
  \item \code{"RSGISLib_Shep"} - RSGISLib Shepherd algorithm;
  \item \code{"OTB_LSMS"} - OTB Large Scale Mean Shift algorithm;
  \item \code{"OTB_LSMS2"} - OTB Large Scale Mean Shift algorithm 
  with two separate sets of parameters, one for mean-shift smoothing 
  and another for large-scale segmentation step;
}}

\item{...}{Additional parameters passed to the segmentation functions that will not be optimized (see also: 
\code{\link{segmentationGeneric}}). It must also contain the input segmentation data (typically a multi-layer 
raster dataset with one input feature per band) depending one the algorithm selected.}

\item{trainThresh}{A threshold value defining the minimum proportion of the segment ]0, 1] that must be covered 
by a certain class to be considered as a training case. This threshold will only apply if \code{x} is a \code{RasterLayer} 
which means you are using train areas/pixels. 
If you are running a \emph{"single-class"} problem then this threshold only applies to the class of interest (coded as 1's). 
Considering this, if a given segment has a proportion cover of that class higher than \code{thresh} then it is 
considered a train case. In contrast, for the background class (coded as 0's), only segments/objects 
totaly covered by that class are considered as train cases.      
If you are running a \emph{"multi-class"} problem then \code{thresh} is applied differently. First, the train class is 
determined by a majority rule then if that class covers more than the value specified in \code{thresh} this case is 
kept in train data otherwise it will be filtered out. See also \code{useThresh}.}

\item{segmStatsFuns}{An aggregation function (e.g., \code{mean}) applied to the elements within each segment. 
Either a function object or a function name.}

\item{bylayer}{Calculate statistics layer by layer instead of all at once? (slightly 
increases computation time but spares memory load; default: FALSE).}

\item{tiles}{Number of times to slice the RasterLayer across row 
and column direction. The total number of tiles will be given by: 
\eqn{N_{tiles} = nd^{2}}.}

\item{classificationMethod}{An input string defining the classification algorithm to be used. Available options are: 
\code{"RF"} (random forests), \code{"GBM"} (generalized boosted models), \code{"SVM"} (support vector machines), \code{"KNN"} 
(k-nearest neighbour), and, \code{"FDA"} (flexible discriminant analysis).}

\item{classificationMethodParams}{A list object with a customized set of parameters to be used for the classification algorithms 
(default = NULL). See also \link{generateDefaultClassifierParams} to see which parameters can be changed and how to structure the 
list object.}

\item{balanceTrainData}{Defines if data balancing is to be used (only available for single-class problems; default: TRUE).}

\item{balanceMethod}{A character string used to set the data balancing method. Available methods are based on under-sampling 
\code{"ubUnder"} or over-sampling \code{"ubOver"} the target class.}

\item{evalMethod}{A character string defining the evaluation method. The available methods are \code{"10FCV"} (10-fold 
cross-validation; the default), \code{"5FCV"} (5-fold cross-validation), \code{"HOCV"} (holdout cross-validation with 
the training percentage defined by \code{trainPerc} and the number of rounds defined in \code{nRounds}), and, \code{"OOB"} 
(out-of-bag evaluation; only applicable to random forests).}

\item{trainPerc}{A decimal number defining the training proportion (default: 0.8; if \code{"HOCV"} is used).}

\item{nRounds}{Number of training rounds used for holdout cross-validation (default: 20; if \code{"HOCV"} is used).}

\item{evalMetric}{A character string setting the evaluation metric or a function that calculates the performance score 
based on two vectors one for observed and the other for predicted values (see below for more details). 
This option defines the outcome value of the genetic algorithm fitness function and the output of grid or random search 
optimization routines. Check \code{\link{evalPerformanceGeneric}} for available options. When \code{runFullCalibration=TRUE} 
this metric will be calculated however other evaluation metrics can be quantified using \link{evalPerformanceClassifier}.}

\item{minTrainCases}{The minimum number of training cases used for calibration (default: 20). If the number of rows 
in \code{x} is below this number then \code{calibrateClassifier} will not run.}

\item{minCasesByClassTrain}{Minimum number of cases by class for each train data split so that the classifier 
is able to run.}

\item{minCasesByClassTest}{Minimum number of cases by class for each test data split so that the classifier 
is able to run.}

\item{minImgSegm}{Minimum number of image segments/objects necessary to generate train data.}

\item{ndigits}{Number of decimal plates to consider for rounding the fitness function output. For example,
if \code{ndigits=2} then only improvements of 0.01 will be considered by the GA algorithm.}

\item{verbose}{Print output messages? (default: TRUE).}
}
\value{
The fitness function value (depends on the option set in \code{evalMetric}).
}
\description{
The fitness function takes a candidate solution to the problem as input (in this case 
the segmentation parameters) and produces an output value measuring how "fit" or how "good" 
the solution is with respect to the problem in hand (i.e., classification performance results).
}
\details{
\emph{"A fitness function is a particular type of objective function that is used to 
summarise, as a single figure of merit, how close a given design solution is to 
achieving the set aims"} (from \href{https://en.wikipedia.org/wiki/Fitness_function}{wikipedia}).      
In particular the fitness function also acts as a 'wrapper' function linking together several 
other in the following worflow sequence:    
 
\enumerate{
  \item Run segmentation and load the results;
  \item Load train data for the segmentation generated;
  \item Extract feature data for the segments (segment statistics calculation);
  \item Merge calibration and feature data;
  \item Do train/test data partitions;
  \item Perform data balancing (if required by user and only for the train and single-class);
  \item Perform classification using the selected algorithm;
  \item Do performance evaluation for each subset;
  \item Return evaluation score (fitness value);
}
}
\seealso{
Check the segmentation parameters and data used by each algorithm that must be 
defined in \code{...}:    
\itemize{
   \item \code{\link{segmentationGeneric}},      
   \item \emph{SAGA Seeded Region Growing}: \code{\link{segmentation_SAGA_SRG}},       
   \item \emph{GRASS Region Growing}: \code{\link{segmentation_GRASS_RG}},       
   \item \emph{ArcGIS Mean Shift}: \code{\link{segmentation_ArcGIS_MShift}},        
   \item \emph{TerraLib Baatz-Schaphe}: \code{\link{segmentation_Terralib_Baatz}},         
   \item \emph{Terralib Mean Region Growing}: \code{\link{segmentation_Terralib_MRGrow}},        
   \item \emph{RSGISLib Shepherd}: \code{\link{segmentation_RSGISLib_Shep}},
   \item \emph{OTB Large Scale Mean Shift}: \code{\link{segmentation_OTB_LSMS}},
   \item \emph{OTB Large Scale Mean Shift with two sets of parameters}: \code{\link{segmentation_OTB_LSMS2}}      
}
}
