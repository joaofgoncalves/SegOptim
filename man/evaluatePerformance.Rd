% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SOptim_PerformanceEval.R
\name{evaluatePerformance}
\alias{evaluatePerformance}
\title{Calculates several performance statistics}
\usage{
evaluatePerformance(obs = NULL, pred = NULL, cm = NULL)
}
\arguments{
\item{obs}{Integer vector with observed values (class labels).}

\item{pred}{Integer vector with predicted values (class labels).}

\item{cm}{A confusion matrix generated by \code{\link{generateConfusionMatrix}} function.}
}
\value{
A list object containing:
   \itemize{
     
     \item Numeric matrix. Holds the confusion matrix;
     
     \item Numeric data frame with several metrics by column:
        \itemize{
         \item Class - class names/numbers,
         \item Accuracy - overall accuracy,
         \item PeirceSkillScore - Peirce skill score (Hanssen and Kuipers discriminant 
         or true skill statistic),
         \item Kappa - Cohen Kappa statistic,
         \item Precision - precision (by class)
         \item Recall - recall (by class)
         \item F1 - F1-statistic (by class).
        }}
}
\description{
A  function used to calculate several performance evaluation metrics, namely:
accuracy, Peirce skill score, and Cohen Kappa (as aggregated performance metrics, 
for all classes) as well as precision, recall and the F1-statistic (for each class).
}
\details{
Adapted from \url{https://github.com/saidbleik/Evaluation/blob/master/eval.R}.
}
\examples{
obs<-sample(c(1:5),100,replace = TRUE)
pred<-sample(c(1:5),100,replace = TRUE)
evaluatePerformance(obs, pred)

}
