% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SOptim_GridSearch.R
\name{searchOptimSegmentationParams}
\alias{searchOptimSegmentationParams}
\title{Perform grid or random search optimization of segmentation/OBIA parameters}
\usage{
searchOptimSegmentationParams(
  rstFeatures,
  trainData,
  segmentMethod,
  ...,
  optimMethod = "random",
  segmParamList,
  grid.searchSize = 5,
  rand.numIter = 250,
  rand.nneigh = 5,
  rand.initNeighs = (5 * rand.nneigh),
  rand.neighSizeProp = 0.025,
  rand.iter = 25,
  trainThresh = 0.5,
  segmStatsFuns = c("mean", "sd"),
  classificationMethod = "RF",
  classificationMethodParams = NULL,
  balanceTrainData = FALSE,
  balanceMethod = "ubUnder",
  evalMethod = "5FCV",
  trainPerc = 0.8,
  nRounds = 20,
  evalMetric = "Kappa",
  minTrainCases = 30,
  minCasesByClassTrain = 10,
  minCasesByClassTest = 10,
  minImgSegm = 30,
  verbose = TRUE,
  parallel = FALSE,
  seed = NULL
)
}
\arguments{
\item{rstFeatures}{Features used for supervised classification (typically a multi-layer SpatRaster with one feature 
per band). May be defined as a string with the path to a raster dataset or a \code{RasterStack} object.}

\item{trainData}{Input train data used for supervised classification. It must be a \code{SpatRaster} containing 
train areas (in raster format)}

\item{segmentMethod}{Character string used to define the segmentation method. 
Available options are:     
\itemize{
  \item \code{"SAGA_SRG"} - SAGA Simple Region Growing;
  \item \code{"GRASS_RG"} - GRASS Region Growing;
  \item \code{"ArcGIS_MShift"} - ArcGIS Mean Shift algorithm;
  \item \code{"Terralib_Baatz"} - TerraLib Baatz algorithm;
  \item \code{"Terralib_MRGrow"} - TerraLib Mean Region Growing;
  \item \code{"RSGISLib_Shep"} - RSGISLib Shepherd algorithm;
  \item \code{"OTB_LSMS"} - OTB Large Scale Mean Shift algorithm;
  \item \code{"OTB_LSMS2"} - OTB Large Scale Mean Shift algorithm 
  with two separate sets of parameters, one for mean-shift smoothing 
  and another for large-scale segmentation step;
}}

\item{...}{Additional parameters passed to the segmentation functions that will not be optimized (see also: 
\code{\link{segmentationGeneric}}). It must also contain the input segmentation data (typically a multi-layer 
SpatRaster dataset with one input feature per band) depending one the algorithm selected.}

\item{optimMethod}{A string defining which type of optimizing to use. Options are: \code{"random"} (default) 
for randomized search, or, \code{"grid"} for exhaustive grid search.}

\item{segmParamList}{A named list object containing the parameters that will be optimized for the selected 
segmentation method. Check parameter names with function \link{segmentationParamNames}. The list should contain two values 
with parameter ranges (min, max). For example, considering method \code{"GRASS_SRG"}, the 
list could be: \code{list(Threshold = c(0.1, 0.5), MinSize = c(10, 50))}.}

\item{grid.searchSize}{This value will be used to extend parameter ranges. For example, if \code{gridSearchSize = 5} 
and a given parameter range is set to p=[0,1] this will generate the following regular sequence: 
\code{p = c(0.00, 0.25, 0.50, 0.75, 1.00)}. All combinations from extended parameters will then be used for grid search 
method.(default: 5)}

\item{rand.numIter}{Number of iteration for random search optimization (default: 250).}

\item{rand.nneigh}{Number of neighbors (or parameter combinations) to generate in the vicinity 
of the best (default: 5).}

\item{rand.initNeighs}{Number of parameter combinations to randomly draw from paramList at initialization 
(default: 5 * nneigh)}

\item{rand.neighSizeProp}{Size of the neighbourhood for a given parameter, i.e., a real value contained 
in ]0, 1] used to multiply the range size as: 
\eqn{neighSize = (max_{range} - min_{range}) \times neighSizeProp}(default: 0.025)}

\item{rand.iter}{Number of sucessive iterations used to stop the algorithm if no improvement is found 
(default: 25).}

\item{trainThresh}{A threshold value defining the minimum proportion of the segment ]0, 1] that must be covered 
by a certain class to be considered as a training case. This threshold will only apply if \code{x} is a \code{RasterLayer} 
which means you are using train areas/pixels. 
If you are running a \emph{"single-class"} problem then this threshold only applies to the class of interest (coded as 1's). 
Considering this, if a given segment has a proportion cover of that class higher than \code{thresh} then it is 
considered a train case. In contrast, for the background class (coded as 0's), only segments/objects 
totaly covered by that class are considered as train cases.      
If you are running a \emph{"multi-class"} problem then \code{thresh} is applied differently. First, the train class is 
determined by a majority rule then if that class covers more than the value specified in \code{thresh} this case is 
kept in train data otherwise it will be filtered out. See also \code{useThresh}.}

\item{segmStatsFuns}{An aggregation function (e.g., \code{mean}) applied to the elements within each segment. 
Either a function object or a function name.}

\item{classificationMethod}{An input string defining the classification algorithm to be used. Available options are: 
\code{"RF"} (random forests), \code{"GBM"} (generalized boosted models), \code{"SVM"} (support vector machines), \code{"KNN"} 
(k-nearest neighbour), and, \code{"FDA"} (flexible discriminant analysis).}

\item{classificationMethodParams}{A list object with a customized set of parameters to be used for the classification algorithms 
(default = NULL). See also \link{generateDefaultClassifierParams} to see which parameters can be changed and how to structure the 
list object.}

\item{balanceTrainData}{Defines if data balancing is to be used (only available for single-class problems; default: TRUE).}

\item{balanceMethod}{A character string used to set the data balancing method. Available methods are based on under-sampling 
\code{"ubUnder"} or over-sampling \code{"ubOver"} the target class.}

\item{evalMethod}{A character string defining the evaluation method. The available methods are \code{"10FCV"} (10-fold 
cross-validation; the default), \code{"5FCV"} (5-fold cross-validation), \code{"HOCV"} (holdout cross-validation with 
the training percentage defined by \code{trainPerc} and the number of rounds defined in \code{nRounds}), and, \code{"OOB"} 
(out-of-bag evaluation; only applicable to random forests).}

\item{trainPerc}{A decimal number defining the training proportion (default: 0.8; if \code{"HOCV"} is used).}

\item{nRounds}{Number of training rounds used for holdout cross-validation (default: 20; if \code{"HOCV"} is used).}

\item{evalMetric}{A character string setting the evaluation metric or a function that calculates the performance score 
based on two vectors one for observed and the other for predicted values (see below for more details). 
This option defines the outcome value of the genetic algorithm fitness function and the output of grid or random search 
optimization routines. Check \code{\link{evalPerformanceGeneric}} for available options. When \code{runFullCalibration=TRUE} 
this metric will be calculated however other evaluation metrics can be quantified using \link{evalPerformanceClassifier}.}

\item{minTrainCases}{The minimum number of training cases used for calibration (default: 20). If the number of rows 
in \code{x} is below this number then \code{calibrateClassifier} will not run.}

\item{minCasesByClassTrain}{Minimum number of cases by class for each train data split so that the classifier 
is able to run.}

\item{minCasesByClassTest}{Minimum number of cases by class for each test data split so that the classifier 
is able to run.}

\item{minImgSegm}{Minimum number of image segments/objects necessary to generate train data.}

\item{verbose}{Print output messages? (default: TRUE).}

\item{parallel}{A logical argument specifying if parallel computing should be used (TRUE) or not (FALSE, default) for 
evaluating the fitness function. This argument could also be used to specify the number of cores to employ; by default, 
this is taken from \link[parallel]{detectCores}. Finally, the functionality of parallelization depends on system OS: on 
Windows only 'snow' type functionality is available, while on Unix/Linux/Mac OSX both 'snow' and 'multicore' (default) 
functionalities are available.}

\item{seed}{An integer value containing the random number generator state. This argument can be used to replicate the results 
of a grid search. Note that if parallel computing is required, the doRNG package must be installed}
}
\value{
A data frame containing the segmentation parameters tested and the respective value of the evaluation metric (by default 
the table is ordered in decreasing order using this column).
}
\description{
This function performs the optimization of segmentation parameters using a simple grid or random search algorithm. It also 
verifies if input data and parameters are parsable.
}
\seealso{
Check the segmentation parameters and data used by each algorithm that must be defined in \code{...} and 
\code{segmParamList}:    
\itemize{
   \item \code{\link{segmentationGeneric}},      
   \item \emph{SAGA Seeded Region Growing}: \code{\link{segmentation_SAGA_SRG}},       
   \item \emph{GRASS Region Growing}: \code{\link{segmentation_GRASS_RG}},       
   \item \emph{ArcGIS Mean Shift}: \code{\link{segmentation_ArcGIS_MShift}},        
   \item \emph{TerraLib Baatz-Schaphe}: \code{\link{segmentation_Terralib_Baatz}},         
   \item \emph{Terralib Mean Region Growing}: \code{\link{segmentation_Terralib_MRGrow}},        
   \item \emph{RSGISLib Shepherd}: \code{\link{segmentation_RSGISLib_Shep}},
   \item \emph{RSGISLib OTB Large Scale Mean Shift}: \code{\link{segmentation_OTB_LSMS}}     
}       
\link{segmentationParamNames} can be used to output a short list of parameter names to include in \code{segmParamList} for 
optimization.
}
